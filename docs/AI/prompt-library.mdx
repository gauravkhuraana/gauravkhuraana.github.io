---
sidebar_position: 3
title: "Prompt Library for Testing & Automation"
description: "A comprehensive collection of AI prompts specifically designed for software testing, test automation, and quality assurance professionals to enhance productivity and code quality."
keywords: ["AI prompts", "testing prompts", "automation prompts", "ChatGPT prompts", "GitHub Copilot prompts", "test automation", "quality assurance", "software testing"]
---

# Prompt Library for Testing & Automation

This comprehensive prompt library contains carefully crafted AI prompts designed specifically for software testing and automation professionals. These prompts are optimized for use with AI tools like ChatGPT, GitHub Copilot, Claude, and other AI assistants to enhance your productivity and code quality.

## Test Automation Framework Development

import YouTubeEmbed from '@site/src/components/YouTubeEmbed';

### Selenium WebDriver Framework Creation

Use this prompt to generate a complete, production-ready test automation framework using Selenium WebDriver and Java.

**Prompt:**

```
Create a modern, scalable, and modular test automation framework using Java 11 or above and Selenium WebDriver that supports cross-browser testing (Chrome, Firefox, Edge)

Key requirements:
• Use TestNG as the test runner
• Follow Page Object Model (POM) design pattern
• Use Maven for build management
• Implement logging (e.g., Log4j or SLF4J) and reporting (e.g., Extent Reports or Allure or both)
• Parallel test execution support for local and remote tests
• A Base Test setup that initializes browser and platform based on config
• Add a pipeline using Github actions and a it should generate a link to allure and extent report
• README and sample tests to show usage
• Test Data should be separate from logic
• Make it compatible with running on Lambdatest platform
• google.com - this site should be used as a sample site for which test should be written

Add these test scenarios (excluding login scenarios):
• A test to check if none of the links are broken
• A test to check if number of images on screen are more than 1
• Write 3-4 tests for the search engine functionality where some should fail and some should pass
```

<YouTubeEmbed 
  videoId="YUOrGS7rDDU" 
  title="Test Automation Framework Development with AI Prompts" 
/>

## Framework Enhancement Prompts

### API Testing Integration

```
Extend the existing Selenium framework to include REST API testing capabilities using RestAssured. Include:
• API base classes and utilities
• JSON schema validation
• Response time assertions
• Data-driven API tests
• Integration with existing reporting
```

### Mobile Testing Addition

```
Add mobile testing capabilities to the existing framework using Appium. Include:
• Mobile driver management for iOS and Android
• Mobile page objects
• Device configuration management
• Cross-platform test execution
• Cloud device integration (Lambdatest / BrowserStack)
```

### REST API Automation Framework Creation

Use this prompt to generate a complete, production-ready API automation framework using REST Assured and Java.

**Prompt:**

```
Create a modern, scalable, and modular API automation framework in Java (Java 17 or 21) using Rest Assured and JUnit as the test runner.

The framework should include the following features:

✅ Supported HTTP Methods
Implement API request support for GET, POST, PUT, DELETE, and PATCH methods.

✅ Authentication Support
Support multiple authentication types:
• Bearer token
• API key
• Basic auth
• Support for setting headers dynamically from properties files or environment.

✅ Serialization / Deserialization
Use POJOs and Jackson/Gson libraries for request payload creation and response parsing.

✅ Framework Structure
Modular folder structure with separation of concerns:
• config, utils, testdata, models, tests, reporting, etc.
• Environment configuration management via .properties or .yaml files.
• Test data management via JSON.

✅ Execution & CI/CD
• Compatible with GitHub Actions and Azure DevOps Pipelines.
• Configurable test execution using Maven profiles or environment tags.

✅ Reporting
• Integrate Extent Reports or Allure Reports for detailed HTML reports.
• Include request/response logs, steps (for failure scenarios).

✅ Logging & Debugging
• Integrate log4j2 or SLF4J for detailed logs.
• Add logs for request/response, headers, and exceptions.
• Enable easy debugging and verbose logs when needed.

✅ Error Handling & Retry Logic
• Add a robust exception handling mechanism.
• Implement retry logic for flaky requests using a custom annotation or Rest Assured filters.

✅ Parallel Execution
Enable parallel execution of tests using JUnit parallel configuration or Maven Surefire plugin.

✅ Docker Support
• Provide a Dockerfile to run the test framework in containers.
• Use a docker-compose.yml file (optional) for service dependencies like mock servers or test APIs.

✅ Test Suites & Tagging
• Organize tests into suites (e.g., smoke, regression, auth tests).
• Use tags/annotations for running specific groups.

✅ Documentation
Provide a README.md with:
• Prerequisites
• Project structure explanation
• How to add a new test case
• How to run tests locally, in Docker, or via pipeline
• Sample command-line usages (e.g., mvn clean test -Denv=qa)

✅ Bonus (Optional Enhancements)
• Integrate with Postman or Swagger to import existing APIs if needed.
• Include utility to generate curl or HAR from failed tests for debugging.
• Add sample validations like status code, headers, response body match.
• Use JSONPath or similar libraries for complex JSON response validation.
• Add data-driven testing capabilities with CSV/Excel support.
```

<YouTubeEmbed 
  videoId="pHMoqzDw2RY" 
  title="REST API Automation Framework Creation with Java and REST Assured" 
/>

## Test Case Generation Prompts

### Comprehensive Test Scenarios

```
Generate comprehensive test scenarios for [APPLICATION_TYPE] covering:
• Functional testing scenarios
• Edge cases and boundary conditions
• Negative test cases
• Performance considerations
• Accessibility requirements
• Cross-browser compatibility checks
```

### Data-Driven Test Creation

```
Create data-driven test cases for [FEATURE_NAME] that include:
• Multiple test data sets in Excel/CSV format
• Parameterized test methods
• Test data validation
• Expected vs actual result comparison
• Detailed test reporting with data sets
```

## Code Review & Quality Prompts

### Code Quality Analysis

```
Review this test automation code for:
• Best practices adherence
• Code maintainability
• Performance optimization opportunities
• Security considerations
• Documentation quality
• Potential flaky test patterns
```

### Test Maintenance

```
Analyze these test cases for maintenance improvements:
• Identify duplicate code patterns
• Suggest refactoring opportunities
• Recommend better locator strategies
• Propose wait strategy improvements
• Suggest reporting enhancements
```

## Debugging & Troubleshooting Prompts

### Test Failure Analysis

```
Analyze this test failure and provide:
• Root cause analysis
• Potential fixes
• Prevention strategies
• Improved error handling
• Better assertion messages
• Debugging recommendations
```

### Performance Optimization

```
Optimize this test automation code for:
• Faster test execution
• Reduced flakiness
• Better resource utilization
• Improved parallel execution
• Memory optimization
• Network call efficiency
```

## Documentation Prompts

### README Generation

```
Create a comprehensive README for this test automation project including:
• Project overview and architecture
• Setup and installation instructions
• Configuration guide
• Test execution commands
• Reporting and results interpretation
• Troubleshooting guide
• Contributing guidelines
```

### Test Plan Documentation

```
Generate a detailed test plan document for [PROJECT_NAME] including:
• Test strategy and approach
• Scope and objectives
• Test environment requirements
• Risk assessment
• Timeline and deliverables
• Success criteria
```

## Usage Tips

### Customizing Prompts

1. **Replace placeholders** like [APPLICATION_TYPE] with specific details
2. **Add context** about your current tech stack and requirements
3. **Specify constraints** like timeline, team size, or technology limitations
4. **Include examples** of existing code or patterns you prefer

### Iterative Refinement

1. **Start with basic prompts** and gradually add complexity
2. **Provide feedback** to the AI about what works and what doesn't
3. **Ask for alternatives** when the first solution doesn't fit your needs
4. **Request explanations** for generated code to improve understanding

### Best Practices

- Always review and test generated code before implementation
- Adapt prompts to match your organization's coding standards
- Keep prompts updated with latest testing trends and technologies
- Share successful prompts with your team for consistency

## Contributing to the Library

Found a useful prompt or want to suggest improvements? 

Connect with me:
- **YouTube**: [Gaurav Khurana Channel](https://youtube.com/@gauravkhurana)
- **Medium**: [Follow my articles](https://medium.com/@gauravkhurana)
- **Topmate**: [Book a session](https://topmate.io/gauravkhurana)

---

*This prompt library is continuously updated with new testing and automation scenarios. Bookmark this page for regular updates and new prompt additions.*
